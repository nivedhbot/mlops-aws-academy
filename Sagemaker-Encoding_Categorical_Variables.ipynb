{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GesksKcvu3s9"
      },
      "source": [
        "# Lab 3.3 -  Encoding Categorical Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxSftoUeu3tE"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This lab does not continue the healthcare-provider scenario. Instead, you will work with data from an [automobile dataset](https://archive.ics.uci.edu/ml/datasets/Automobile).\n",
        "\n",
        "In this lab, you will:\n",
        "\n",
        "- Encode ordinal categorical data\n",
        "- Encode non-ordinal categorical data\n",
        "\n",
        "## About this dataset\n",
        "\n",
        "This dataset consists of three types of entities:\n",
        "\n",
        "1. The specification of an automobile in terms of various characteristics\n",
        "2. Its assigned insurance risk rating\n",
        "3. Its normalized losses in use compared to other cars\n",
        "\n",
        "The second rating corresponds to the degree to which the automobile is riskier than its price indicates. Cars are initially assigned a risk factor symbol that's associated with its price. Then, if it's riskier (or less risky), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process *symboling*. A value of *+3* indicates that the car is risky. A value of *-3* indicates that the car is probably safe.\n",
        "\n",
        "The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all cars within a particular size classification (two-door small, station wagons, sports or speciality, and others). It represents the average loss per car per year.\n",
        "\n",
        "**Note:** Several attributes in the database could be used as a *class* attribute.\n",
        "\n",
        "## Attribute information\n",
        "\n",
        "Attribute: Attribute Range\n",
        "\n",
        "1. symboling: -3, -2, -1, 0, 1, 2, 3.\n",
        "1. normalized-losses: continuous from 65 to 256.\n",
        "1. fuel-type: diesel, gas.\n",
        "1. aspiration: std, turbo.\n",
        "1. num-of-doors: four, two.\n",
        "1. body-style: hardtop, wagon, sedan, hatchback, convertible.\n",
        "1. drive-wheels: 4wd, fwd, rwd.\n",
        "1. engine-location: front, rear.\n",
        "1. wheel-base: continuous from 86.6 120.9.\n",
        "1. length: continuous from 141.1 to 208.1.\n",
        "1. width: continuous from 60.3 to 72.3.\n",
        "1. height: continuous from 47.8 to 59.8.\n",
        "1. curb-weight: continuous from 1488 to 4066.\n",
        "1. engine-type: dohc, dohcv, l, ohc, ohcf, ohcv, rotor.\n",
        "1. num-of-cylinders: eight, five, four, six, three, twelve, two.\n",
        "1. engine-size: continuous from 61 to 326.\n",
        "1. fuel-system: 1bbl, 2bbl, 4bbl, idi, mfi, mpfi, spdi, spfi.\n",
        "1. bore: continuous from 2.54 to 3.94.\n",
        "1. stroke: continuous from 2.07 to 4.17.\n",
        "1. compression-ratio: continuous from 7 to 23.\n",
        "1. horsepower: continuous from 48 to 288.\n",
        "1. peak-rpm: continuous from 4150 to 6600.\n",
        "1. city-mpg: continuous from 13 to 49.\n",
        "1. highway-mpg: continuous from 16 to 54.\n",
        "1. price: continuous from 5118 to 45400.\n",
        "\n",
        "## Dataset attributions\n",
        "\n",
        "This dataset was obtained from:\n",
        "Dua, D. and Graff, C. (2019). UCI Machine Learning Repository (http://archive.ics.uci.edu/ml). Irvine, CA: University of California, School of Information and Computer Science."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mzhgvgpu3tG"
      },
      "source": [
        "# Step 1: Importing and exploring the data\n",
        "\n",
        "You will start by examining the data in the dataset.\n",
        "\n",
        "To get the most out of this lab, read the instructions and code before you run the cells. Take time to experiment!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWQf8DzWu3tH"
      },
      "source": [
        "Start by importing the pandas package and setting some default display options."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlOirl6Tu3tH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-o0XD4uu3tL"
      },
      "source": [
        "Next, load the dataset into a pandas DataFrame.\n",
        "\n",
        "The data doesn't contain a header, so you will define those column names in a variable that's named `col_names` to the attributes listed in the dataset description.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBD22SVru3tL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "95cf92ed-5182-41be-b219-305bf03c0ad1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'imports-85.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-964424323.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                                     'fuel-system','bore','stroke','compression-ratio','horsepower','peak-rpm','city-mpg','highway-mpg','price']\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf_car\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol_names\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mna_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"?\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'imports-85.csv'"
          ]
        }
      ],
      "source": [
        "url = \"imports-85.csv\"\n",
        "col_names=['symboling','normalized-losses','fuel-type','aspiration','num-of-doors','body-style','drive-wheels','engine-location','wheel-base',\n",
        "                                    'length','width','height','curb-weight','engine-type','num-of-cylinders','engine-size',\n",
        "                                    'fuel-system','bore','stroke','compression-ratio','horsepower','peak-rpm','city-mpg','highway-mpg','price']\n",
        "\n",
        "df_car = pd.read_csv(url,sep=',',names = col_names ,na_values=\"?\",  header=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Guj5oev7u3tM"
      },
      "source": [
        "First, to see the number of rows (instances) and columns (features), you will use `shape`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAXPfwJ1u3tN"
      },
      "outputs": [],
      "source": [
        "df_car.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsOcgM9ru3tO"
      },
      "source": [
        "Next, examine the data by using the `head` method.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsRBe4wJu3tO"
      },
      "outputs": [],
      "source": [
        "df_car.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hYhlZNru3tP"
      },
      "source": [
        "There are 25 columns. Some of the columns have numerical values, but many of them contain text.\n",
        "\n",
        "To display information about the columns, use the `info` method.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hcWrQXSu3tP"
      },
      "outputs": [],
      "source": [
        "df_car.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2Eqn9M8u3tP"
      },
      "source": [
        "To make it easier to view the dataset when you start encoding, drop the columns that you won't use.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISbIG8C-u3tQ"
      },
      "outputs": [],
      "source": [
        "df_car.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXswFRBWu3tQ"
      },
      "outputs": [],
      "source": [
        "df_car = df_car[[ 'aspiration', 'num-of-doors',  'drive-wheels',  'num-of-cylinders', 'body-style', 'engine-type', 'fuel-type']].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISfg0hGtu3tR"
      },
      "source": [
        "You now have four columns. These columns all contain text values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_7kchQDu3tR"
      },
      "outputs": [],
      "source": [
        "df_car.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdc9mj3Ru3tR"
      },
      "source": [
        "Most machine learning algorithms require inputs that are numerical values.\n",
        "\n",
        "- The **num-of-cylinders** and **num-of-doors** features have an ordinal value. You could convert the values of these features into their numerical counterparts.\n",
        "- However, **aspiration** and **drive-wheels** don't have an ordinal value. These features must be converted differently.\n",
        "\n",
        "You will explore the ordinal features first.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzmL7ktiu3tS"
      },
      "source": [
        "# Step 2: Encoding ordinal features\n",
        "\n",
        "In this step, you will use a mapper function to convert the ordinal features into ordered numerical values.\n",
        "\n",
        "Start by getting the new column types from the DataFrame:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pXXi6dsu3tS"
      },
      "outputs": [],
      "source": [
        "df_car.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98JQXtXgu3tS"
      },
      "source": [
        "First, determine what values the ordinal columns contain.\n",
        "\n",
        "Starting with the **num-of-doors** feature, you can use `value_counts` to discover the values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHKGVMjiu3tT"
      },
      "outputs": [],
      "source": [
        "df_car['num-of-doors'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zdsvAfMu3tT"
      },
      "source": [
        "This feature only has two values: *four* and *two*. You can create a simple mapper that contains a dictionary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwFl_6K4u3tT"
      },
      "outputs": [],
      "source": [
        "door_mapper = {\"two\": 2,\n",
        "              \"four\": 4}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iB8L08uNu3tU"
      },
      "source": [
        "You can then use the `replace` method from pandas to generate a new numerical column based on the **num-of-doors** column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GS1hwkhsu3tU"
      },
      "outputs": [],
      "source": [
        "df_car['doors'] = df_car[\"num-of-doors\"].replace(door_mapper)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtks3Lpau3tU"
      },
      "source": [
        "When you display the DataFrame, you should see the new column on the right. It contains a numerical representation of the number of doors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jTNDLLnu3tU"
      },
      "outputs": [],
      "source": [
        "df_car.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61Ewp0nWu3tV"
      },
      "source": [
        "Repeat the process with the **num-of-cylinders** column.\n",
        "\n",
        "First, get the values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7CKWDiCu3tV"
      },
      "outputs": [],
      "source": [
        "df_car['num-of-cylinders'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaj_PYS9u3tV"
      },
      "source": [
        "Next, create the mapper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woUuDzOmu3tW"
      },
      "outputs": [],
      "source": [
        "cylinder_mapper = {\"two\":2,\n",
        "                  \"three\":3,\n",
        "                  \"four\":4,\n",
        "                  \"five\":5,\n",
        "                  \"six\":6,\n",
        "                  \"eight\":8,\n",
        "                  \"twelve\":12}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCXi17spu3tW"
      },
      "source": [
        "Apply the mapper by using the `replace` method.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whbKDFGtu3tW"
      },
      "outputs": [],
      "source": [
        "df_car['cylinders'] = df_car['num-of-cylinders'].replace(cylinder_mapper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwnHUwrhu3tW"
      },
      "outputs": [],
      "source": [
        "df_car.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3nkwV1Du3tX"
      },
      "source": [
        "For more information about the `replace` method, see [pandas.DataFrame.replace](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html) in the pandas documentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7fV7Cvtu3tX"
      },
      "source": [
        "# Step 3: Encoding non-ordinal categorical data\n",
        "\n",
        "In this step, you will encode non-ordinal data by using the `get_dummies` method from pandas.\n",
        "\n",
        "The two remaining features are not ordinal.\n",
        "\n",
        "According to the attribute description, the following values are possible:\n",
        "\n",
        "- aspiration: std, turbo.\n",
        "- drive-wheels: 4wd, fwd, rwd.\n",
        "\n",
        "You might think that the correct strategy is to convert these values into numerical values. For example, consider the **drive-wheels** feature. You could use *4wd = 1*, *fwd = 2*, and *rwd = 3*. However, *fwd* isn't less than *rwd*. These values don't have an order, but you just introduced an order to them by assigning these numerical values.\n",
        "\n",
        "The correct strategy is to convert these values into *binary features* for each value in the original feature. This process is often called *one-hot encoding* in machine learning, or *dummying* in statistics.\n",
        "\n",
        "pandas provides a `get_dummies` method, which converts the data into binary features. For more information, see [pandas.get_dummies](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) in the pandas documentation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq6vnoETu3td"
      },
      "source": [
        "According to the attribute description, **drive-wheels** has three possible values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1CXnjxwu3td"
      },
      "outputs": [],
      "source": [
        "df_car['drive-wheels'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rF-usWzu3te"
      },
      "source": [
        "Use the `get_dummies` method to add new binary features to the DataFrame.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQ08Uot0u3te"
      },
      "outputs": [],
      "source": [
        "df_car = pd.get_dummies(df_car,columns=['drive-wheels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5K21LjZfu3te"
      },
      "outputs": [],
      "source": [
        "df_car.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI0dgEKFu3te"
      },
      "source": [
        "When you examine the dataset, you should see three new columns on the right:\n",
        "\n",
        "- **drive-wheels_4wd**\n",
        "- **drive-wheels_fwd**\n",
        "- **drive-wheels_rwd**\n",
        "\n",
        "The encoding was straightforward. If the value in the **drive-wheels** column is *4wd*, then a *1* is the value in the **drive-wheels_4wd** column. A *0* is the value for the other columns that were generated. If the value in the **drive-wheels** column is *fwd*, then a *1* is the value in the **drive-wheels_fwd** column, and so on.\n",
        "\n",
        "These binary features enable you to express the information in a numerical way, without implying any order.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nR3J8Z7u3te"
      },
      "source": [
        "Examine the final column that you will encode.\n",
        "\n",
        "The data in the **aspiration** column only has two values: *std* and *turbo*. You could encode this column into two binary features. However, you could also ignore the *std* value and record whether it's *turbo* or not. To do this, you would still use the `get_dummies` method, but specify `drop_first` as *True*.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKXJldISu3tf"
      },
      "outputs": [],
      "source": [
        "df_car['aspiration'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43eei03ou3tf"
      },
      "outputs": [],
      "source": [
        "df_car = pd.get_dummies(df_car,columns=['aspiration'], drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKE01tsDu3tf"
      },
      "outputs": [],
      "source": [
        "df_car = pd.get_dummies(df_car, columns=['body-style', 'engine-type'])\n",
        "df_car = pd.get_dummies(df_car,columns=['fuel-type'], drop_first=True)\n",
        "df_car.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43HvsdyXu3tf"
      },
      "source": [
        "**Challenge task:** Go back to the beginning of this lab, and add other columns to the dataset. How would you encode the values of each column? Update the code to include some of the other features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycdEgHalu3tf"
      },
      "source": [
        "# Congratulations!\n",
        "\n",
        "You have completed this lab, and you can now end the lab by following the lab guide instructions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pFs99vfu3tg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "conda_python3",
      "language": "python",
      "name": "conda_python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}